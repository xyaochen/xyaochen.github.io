<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xuanyao Chen</title>
  
  <meta name="author" content="Xuanyao Chen">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xuanyao Chen</name>
              </p>
              <p>I am now a quant researcher at a prop shop, Shanghai.
              
                During my undergraduate at Fudan University, I had the opportunity to work with Prof. <a href="https://songhan.mit.edu/">Song Han</a> at MIT HANLab on efficient learning, with Prof. <a href="https://hangzhaomit.github.io/">Hang Zhao</a> on autonomous driving and multimodal learning, and with Prof. <a href="https://ericyi.github.io/">Li Yi</a> on 3D vision.
              </p>
              <p>
                Email: ixyaochen [at] gmail [dot] com
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=PVk1xQoAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/xyaochen">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/xuanyao.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xuanyao.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        

        <h2>Selected Publications</h2>
		<ul>
			<li>
				<p>
					<b>SparseVit: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer</b> 
					
					<br> <strong>Xuanyao Chen*</strong>, Zhijian Liu*, Haotian Tang, Li Yi, Hang Zhao, Song Han<br>
					CVPR 2023  <a href="https://arxiv.org/abs/2303.17605">paper</a> / <a href="https://sparsevit.mit.edu/">Project Page</a>
				</p>
		</ul>

    <ul>
			<li>
				<p>
					<b>FUTR3D: A Unified Sensor Fusion Framework for 3D Detection</b> 
					
					<br> <strong>Xuanyao Chen</strong>, Tianyuan Zhang, Yue Wang, Yilun Wang, Hang Zhao<br>
					CVPR 2023 Workshop on Autonomous Driving <a href="https://arxiv.org/abs/2203.10642">paper</a> / <a href="https://tsinghua-mars-lab.github.io/futr3d/">Project Page</a>
				</p>
		</ul>

    <ul>
			<li>
				<p>
					<b>ViP3D: End-to-end Visual Trajectory Prediction via 3D Agent Queries</b> 
					
					<br> Junru Gu, Chenxu Hu, Tianyuan Zhang, Xuanyao Chen, Yilun Wang, Yue Wang, Hang Zhao<br>
					CVPR 2023  <a href="https://arxiv.org/abs/2208.01582">paper</a> 
		</ul>

    <ul>
			<li>
				<p>
					<b>MUTR3D: A Multi-camera Tracking Framework via 3D-to-2D Queries</b> 
					
					<br> Tianyuan Zhang, Xuanyao Chen, Yue Wang, Yilun Wang, Hang Zhao<br>
					CVPR 2022 Workshop on Autonomous Driving <a href="https://arxiv.org/abs/2205.00613">paper</a> 
		</ul>

    <ul>
			<li>
				<p>
					<b>What Makes Multi-modal Learning Better than Single (Provably)</b> 
					
					<br> Yu Huang, Chenzhuang Du, Zihui Xue, Xuanyao Chen, Hang Zhao, Longbo Huang<br>
					NeurIPS 2021 <a href="https://arxiv.org/abs/2106.04538">paper</a> 
		</ul>

    <h2>Selected Awards</h2>
        <ul>
          <li>2023: Outstanding graduates in Fudan University </li>
          <li>2022: SenseTime Scholarship (30 undergrads all over China)</li>
          <li>2022: Fanhai Scholarship (10 undergrads in Fudan University)</li>
          <li>2021: Samsung Scholarship </li>
          <li>2021: The First Price, Chinese Undergraduate Mathematics Competition (rank Top10 in Shanghai)</li>
          <li>2020: National Scholarship </li>
          
        </ul>


    <h2>Academic Service</h2>
    I served as a reviewer in CoRL 2022, CVPR 2023, NeurIPS 2023, ICLR 2024.

      </td>
    </tr>
  </table>
</body>

</html>
